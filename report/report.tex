\documentclass{article}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{amsmath} % For math symbols
\usepackage{graphicx} % For including images
\usepackage{booktabs} % For table formatting
\usepackage{multirow} % For multirow in tables
\usepackage{float} % For float positioning option H
\usepackage[utf8]{inputenc}
\usepackage[colorlinks=true,linkcolor=blue,citecolor=blue,filecolor=blue,urlcolor=blue]{hyperref}
%\usepackage{algorithm}
%\usepackage{algpseudocode}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}


\begin{document}
\title{INF421 PI\@: PATH PLANNING ALGORITHMS}
\author{Merouane Benadda, Antoine FÃ¨vre}

\maketitle

In this project, we implemented two path planning algorithms: Particle Swarm Optimization (PSO) and Rapidly-exploring Random Tree (RRT). Path planning is a fundamental problem in robotics and artificial intelligence, where the goal is to find a path from a start point to a goal point while avoiding obstacles. In our case, the environment is a rectangular area with randomly placed rectangular obstacles.

\bigskip

\textbf{Question 1.} We chose to implement the algorithm in C++, as it allows better performance. 
For visualization, we used Python with Matplotlib, as it provides a more convenient way to create visual representations of the results.

The corresponding method can be found in the file \texttt{src/Problem.cpp}.

\medskip

\textbf{Question 2.} See the implementation in the file \texttt{scripts/visualize.py}.

\medskip

\textbf{Question 3.} See the implementation in the file \texttt{src/pso.cpp}.
Our fitness function is defined as the euclidian distance of the path, plus infinity if the path crosses an obstacle. This way, the algorithm will try to find a valid path that minimizes the distance to the goal point.

\medskip

\textbf{Question 4.} See the implementation in the file \texttt{src/pso.cpp}.

\medskip

\textbf{Question 5.} See Algorithm~\ref{alg:pso} for the pseudocode in the appendix.

\medskip

\textbf{Question 6.} The complexity of the algorithm is $O(I \cdot N \cdot M)$, where $I$ is the number of iterations, $N$ is the number of particles in the swarm, and $M$ is the number of waypoints in each particle's path. 

Indeed, for each iteration, we evaluate the fitness of each particle, which takes $O(N \cdot M)$ time, since we compute the fitness by iterating over each waypoint in each particle's path. Then, we update the velocity and position of each particle, which also takes $O(N \cdot M)$ time, as we need to update each waypoint for each particle. Therefore, the overall complexity is $O(I \cdot N \cdot M)$.

\medskip

\textbf{Question 7.} See the implementation in the file \texttt{src/pso.cpp}.
We implemented the algorithm following the pseudocode given for question 5. We initialize the particles with random waypoints, and then we iteratively evaluate their fitness, update their memory of the best position, and update their velocity and position according to the PSO equations. We also ensure that the waypoints stay within the bounds of the environment by clamping their coordinates after each update.

\medskip

\textbf{Question 8.} For the basic PSO algorithm, we had to pick an important number of particles because, since our fitness function is quite simple (the euclidian distance plus infinity if the path crosses an obstacle), finding a first valid path is a matter of luck, and the more particles we have, the more likely we are to find a valid path that we can optimize.

As we can see in Figure~\ref{fig:scenarios}, the solutions are not always optimal.

\begin{verbatim}
const int NUM_PARTICLES = 100000;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 1000;
const double C1 = 2.0; // cognitive coefficient
const double C2 = 2.0; // social coefficient
const double W = 0.75;  // inertia weight
\end{verbatim}

\medskip

\textbf{Question 9.}

The random restart method allows us to reduce the number of particles needed to find a valid path, as it gives the algorithm multiple chances to find a valid path by restarting the particles' positions after a certain number of iterations. This way, even if we start with a small number of particles, we can still find a valid path by giving the algorithm multiple attempts. The restart interval is sufficiently large to allow the particles to explore the search space and converge towards a good solution before being restarted.

\begin{verbatim}
const int NUM_PARTICLES = 1000;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 50000;
const int RESTART_INTERVAL = 2500;
\end{verbatim}


\medskip

\textbf{Question 10.} The cooling rate makes the temperature stay high for a longer time, which allows the algorithm to explore the search space more thoroughly and avoid getting stuck in local minima. We chose the initial temperature empirically, by testing different values and observing the convergence of the algorithm.


\begin{verbatim}
const int NUM_PARTICLES = 1000;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 30000;
const int RESTART_INTERVAL = 3000;
double initial_temperature = 100.0;
double cooling_rate = 0.99;
\end{verbatim}


\medskip

\textbf{Question 11.}

We chose a small stagnation threshold so the particles can quickly benefit from the dimensional learning when they are stuck in a local minimum. Since our fitness function is quite simple, it is easy for the particles to get stuck in local minima, especially in scenarios with many obstacles. By applying dimensional learning after a small number of iterations without improvement, we allow the particles to escape these local minima and explore new areas of the search space, which can lead to better solutions.

\begin{verbatim}
const int NUM_PARTICLES = 500;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 30000;
const int RESTART_INTERVAL = 5000;
double initial_temperature = 100.0;
double cooling_rate = 0.99;
int stagnation_threshold = 15;
\end{verbatim}

\medskip

\textbf{Question 12.} To improve the performance of the algorithm, we can refine the fitness function. Instead of simply being the euclidian distance plus infinity if the path crosses an obstacle, we can make it output the euclidian distance plus a penalty proportional to the distance crossed in the obstacles.

This way, the algorithm would converge faster, especially in cases with lots of obstacles, as it would be able to differentiate between paths that are close to the optimal one but cross an obstacle and paths that are far from the optimal one but do not cross any obstacle.

To do so, we compute the intersection of the path with the obstacles in \texttt{src/utils.cpp}. To avoid any situation where the algorithm would prefer crossing an obstacle to reduce the distance, we can set the penalty to be a large constant multiplied by the distance crossed in the obstacle.

\begin{verbatim}
const int NUM_PARTICLES = 200;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 30000;
const int RESTART_INTERVAL = 2500;
double initial_temperature = 100.0;
double cooling_rate = 0.999;
int stagnation_threshold = 15;
\end{verbatim}

\medskip


\begin{table}[ht]
\centering
\caption{Performance Comparison across All Test Scenarios and Methods}
\label{tab:all_results}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}l|rr|rr|rr|rr|rr@{}}
\toprule
\multirow{2}{*}{\textbf{Scenario}} & \multicolumn{2}{c|}{\textbf{Basic PSO}} & \multicolumn{2}{c|}{\textbf{Random Restart}} & \multicolumn{2}{c|}{\textbf{Annealing PSO}} & \multicolumn{2}{c|}{\textbf{Dim. Learning}} & \multicolumn{2}{c}{\textbf{DL + Refined Fitness}} \\
& \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} \\
\midrule
0 & 1443.33 & 22.72 & 1443.33 & 10.65 & 1443.33 & 7.82 & 1443.33 & 5.00 & 1443.33 & 1.29 \\
1 & 1449.06 & 31.06 & 1449.06 & 15.17 & 1449.06 & 10.70 & 1449.06 & 7.38 & 1449.12 & 1.45 \\
2 & 1522.56 & 37.66 & 1505.19 & 18.20 & 1505.19 & 12.99 & 1505.65 & 7.32 & 1505.19 & 1.91 \\
3 & 1524.98 & 34.25 & 1522.54 & 16.23 & 1522.90 & 10.43 & 1522.52 & 6.36 & 1522.86 & 2.23 \\
4 & 1961.92 & 35.89 & 1946.06 & 16.81 & 1948.74 & 10.55 & 1946.45 & 6.33 & 1941.36 & 2.30 \\
\bottomrule
\end{tabular}%
}
\end{table}

As we can see in Table~\ref{tab:all_results}, adding the different improvements to the basic PSO algorithm allows us to significantly reduce the cost of the solution and the time needed to find it. The final algorithm outputs a path that is very close to the optimal one, and does so in a reasonable amount of time, even in the most complex scenarios.

\medskip

\textbf{Question 13.}

To represent the tree, we use three vectors. For each vertex index, we have the corresponding point in the \texttt{vertices} vector, the index of its parent vertex in the \texttt{parents} vector, and the distance of the path from the root to the vertex in the \texttt{costs} vector. This way, we can easily reconstruct the path from any vertex to the root by following the parent indices, and efficiently compute the length of any path in the tree when updating parents in the rewiring process.
See the implementation in the file \texttt{src/RRT.hpp}.

\medskip

\textbf{Question 14.}

To correspond to the conventions taken before, the method gives the vertices coordinates, from the root to the goal, excluding the extremities.
See the implementation in the files \texttt{src/RRT.hpp} and \texttt{src/RRT.cpp}.

\medskip

\textbf{Question 15.}

Most of the work is done by BuildRRT (Algorithm \ref{alg:rrt}), which builds the tree. RRTPath (Algorithm \ref{RRTPath}) only calls BuildRRT, and then reconstructs the path with reconstructPath implemented in Question 14.

The method addVertex (Algorithm \ref{AddVertex}) is used to update the tree, given a point and the parent vertex.



\medskip

\textbf{Question 16.}

For one iteration of the while loop of the algorithm BuildRRT, the time complexity is a $O(NM)$, where $N$ is the number of nodes in the tree and $M$ the number of obstacles. Indeed, the two loops at lines 16-20 and 25-30 take at most that amount of time, as in the worst case all vertices are at a distance to $v$ lower than $\delta_s$, and all obstacles have to be tried.
All other instructions in an iteration have a strictly lower complexity than that.

If a tree is built before reaching the maximum number of iterations $I_{max}$, at the iteration $i$, there are less than $i$ vertices in the tree, as there is at most one node created by iteration. That is why, overall, the time complexity is $O(M I^2)$, where $I$ iterations are necessary to build a tree reaching the goal point.
Indeed \texttt{reconstructTree} takes at most $O(I)$ time in execution.

The hyperparameter $\delta_s$ has an impact on real time execution. Increasing it might reduce the number of iterations needed, as each one makes a more significant advance. However, this increases the complexity at each iteration because more vertices will be at a lower distance from $v$ than $\delta_s$

\medskip

\textbf{Question 17.}

See the implementation in the file \texttt{RRT.cpp}.

\medskip

\textbf{Question 18.}

I initially chose, for the hyperparameters $\delta_s = 100$ and $\delta_r = 100$. Considering the size of the zone (1000*1000), it seemed appropriate. After trying on different scenarios, it appears that increasing $delta_s$ gives best results in areas with few obstacles.

Here are the results for $\delta_s = 100$ and $\delta_r = 100$:

\begin{table}[ht]
\centering
\caption{RRT results for different scenarios}
\label{tab:rrt_results}
%\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}l|c|c|c@{}}
\toprule
\textbf{Scenario} & \textbf{Path length} & \textbf{Iterations} & \textbf{CPU Time (s)} \\
\midrule
0 & 1742.09 & 224 & 0 \\
1 & 1718.12 & 533 & 0.002 \\
2 & 1739.89 &  242 & 0.001 \\
3 & 1757.14 & 410 & 0.004 \\
4 & 2186.43 & 721 & 0.009 \\
\bottomrule
\end{tabular}%
\end{table}

\medskip

\textbf{Question 19.}

The path built are made of segments of length at most $\delta_s$. However, there is sometimes a free space longer than $\delta_s$ to cross, which is made by assembling multiple segments. As these segments do not have the same direction, the path is not optimal, according to the triangle inequality.
Indeed, it is more efficient to supress intermediate nodes in the path, if the lines created do not cross any obstacle.

To do so, we keep the same path building method, but we improve the returned path by supressing intermediate nodes.

See the implementation in the method \texttt{optimizePath}, in file \texttt{src/RRT.cpp}.

Thus the complexity of the algorithm remains the same, as the optimization step is done in $O(I)$ time, where $I$ is the number of iterations needed to build the tree, which is negligible compared to the complexity of building the tree. This is confirmed by the results, the computation time of optimization is equal to 0s in all scenarios.
\medskip

\textbf{Question 20.}

Results are shown in Table~\ref{tab:rrt_optimized_results}. For the RRT, as the path optimization complexity is negligible compared to the tree building, results shown come from the same tree building.
Moreover, this allows to compare the path length before and after optimization on one single tree, making the comparison more relevant.
The metrics for PSO are taken from the DL + Refined fitness version.

\begin{table}[ht]
\centering
\caption{Performance comparison between PSO and RRT (without and with optimized path)}
\label{tab:rrt_optimized_results}

\begin{tabular}{@{}l|ccc|cc@{}}
\toprule
\multirow{2}{*}{\textbf{Scenario}} & \multicolumn{3}{c|}{\textbf{Path length}} & \multicolumn{2}{c}{\textbf{CPU time (s)}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-6}
& \textbf{PSO} & \textbf{RRT} & \textbf{RRT (optimized path)} & \textbf{PSO} & \textbf{RRT} \\
\midrule
0 & 1443.33 & 1785,36 & 1437,43 & 1.29 & 0 \\
1 & 1449.12 & 1810,40 & 1433,18 & 1.45 & 0.002 \\
2 & 1505.19 & 1975,92 & 1525,40 & 1.91 & 0 \\
3 & 1522.86 & 1643,85 & 1515,43 & 2.23 & 0 \\
4 & 1941.36 & 2319,06 & 2006,87 & 2.30 & 0.016 \\
\bottomrule
\end{tabular}
\end{table}

\medskip

\textbf{Question 21.}

We change BuildRRT (Algorithm \ref{alg:rrt}) to use intelligent sampling as shown in \ref{alg:rrt_intelligent}.

To do so, we use Algorithm \ref{alg:intelligent_sample} to sample points next to a vertex, near an obstacle, or uniformly random depending on probability parameters $p_v$ and $p_e$.

The sampled points are chosen among pre-computed vectors of satisfying points. They are made with Algorithms \ref{verticesObstacles} and \ref{PointsNearObstacles}.


\medskip

\textbf{Question 22.}

See the implementation in files \texttt{src/RRT.cpp}, \texttt{src/Problem.cpp} and \texttt{src/utils.cpp}.

This approach leads to introducing three new hyperparameters. 
The number of samples to create near the obstacles was fixed based on previous experiments, so that we have enough points to try over all the iteration but we do not compute too many uselessly. Thus we chose \texttt{num\_points\_near\_obstacles = 1000}. 
The probabilities $p_v$ and $p_e$ were chosen to efficiently target corners, which are key points for efficient paths. However, setting $p_v$ too high is not relevant, as this would create too much branches of the tree directed towards uninteresting corners. That is why we chose $p_v = 0.4$. It is the same idea for edge sampling : if the probability is too low, we do not focus enough on edges. If it is too high, we overfocus on some edges, even though they are irrelevant for our problem. That is why we chose $p_e = 0.3$, so that we have a fairly exhaustive exploration of edges without trying every precomputed point.

\medskip

\textbf{Question 23.}

When considering both methods developed previously, RRT seems to the most appropriate when there are two robots. Indeed, it appears to be the most efficient, and it is editable quite easily to consider a second robot.

The idea is to find a path for the first robot, and then to build a new tree following RRT rules with a new constraint : the new tree should not cut the path of the first robot at a time when it could. To do so, and in order to avoid delay changes due to rewiring, this second tree will be build without rewiring. If the new tree crosses the path, we will check that the distance from the root is not distant from the one one the path from less than $2R$, so that robots won't collide.

To do so, we changed every method to take into account if the robot is the first or the second robot.



\textbf{Question 24.} Unfortunately, we were not able to implement the multi-robot version of RRT. We had the pseudocode and the general idea of the implementation, but we were not able to make it work because of a segmentation fault that we could not debug in time.



\medskip

\textbf{Question 25.} We used Github for version control and to share our code. It is a very convenient tool for collaboration, as it allows us to easily track changes, manage branches, and review each other's code.

We also used GitHub Copilot to help us with some of the redundant code, such as the verification of the input or the geometry functions. It is a very useful tool for increasing productivity, as it can generate code snippets based on the context, which saves us time and allows us to focus on the more complex parts of the implementation. However, we used it very carefully, as it can sometimes generate incorrect code, so we always reviewed the generated code line by line to ensure its correctness.

\medskip

\appendix

\section{Pseudo-code}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

    \Input{Problem scenario $P$, iterations $I$, constants $c_1, c_2, w$}
    \Output{Global best path $g_{best}$ and its cost $f(g_{best})$}

    \BlankLine
    Initialize $g_{best}$ with the first particle's waypoints\;
    \For{$iter = 1$ \KwTo$I$}{
        \BlankLine
        \tcp{Evaluate Fitness and Update Memory}
        \ForEach{particle $p$ in swarm}{
            $cost \leftarrow \text{fitness}(p.waypoints, P)$\;
            
            \If{$cost < p.best\_cost$}{
                $p.best\_cost \leftarrow cost$\;
                $p.best\_waypoints \leftarrow p.waypoints$\;
            }
            
            \If{$cost < g_{best}.cost$}{
                $g_{best}.cost \leftarrow cost$\;
                $g_{best}.waypoints \leftarrow p.waypoints$\;
            }
        }

        \BlankLine
        \tcp{Update Kinematics}
        \ForEach{particle $p$ in swarm}{
            \For{each waypoint $i$ in path}{
                $r_1, r_2 \leftarrow \text{random}(0, 1)$\;
                
                \tcp{Velocity Update}
                $v_i \leftarrow w \cdot v_i + c_1 \cdot r_1 \cdot (p.best\_waypoints_i - p.waypoints_i) + c_2 \cdot r_2 \cdot (g_{best}.waypoints_i - p.waypoints_i)$\;
                
                \tcp{Position Update}
                $p.waypoints_i \leftarrow p.waypoints_i + v_i$\;
                
                \tcp{Boundary Constraint}
                $p.waypoints_i \leftarrow \text{clamp}(p.waypoints_i, P.\min, P.\max)$\;
            }
        }
    }
    \Return{$g_{best}$}
    \caption{Particle Swarm Optimization for Path Planning}\label{alg:pso}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \SetKwProg{Fn}{Function}{:}{}
    
    \Fn{\textsc{AddVertex}$(v, parent\_index)$}{
        Append $v$ to $tree.vertices$\;
        Append $parent\_index$ to $tree.parents$\;
        $cost \leftarrow tree.costs[parent\_index] + d(tree.vertices[parent\_index], v)$\;
        Append $cost$ to $tree.costs$\;
    }
    \caption{AddVertex - Add a vertex to the tree}
    \label{AddVertex}
\end{algorithm}


\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \Input{Problem $P$, step size $\delta_s$, rewiring radius $\delta_r$, max iterations $I_{max}$}
    \Output{Tree connecting start to goal}
    \BlankLine
    $iterations \leftarrow 0$\;
    \While{$iterations < I_{max}$}{
        \BlankLine
        \tcp{Sample Random Point}
        $v_r \leftarrow$ random point in $[0, P.x_{max}] \times [0, P.y_{max}]$\;
        
        \If{$v_r$ is inside an obstacle}{
            \textbf{continue}\;
        }
        \BlankLine
        \tcp{Find Nearest Vertex}
        $v_n \leftarrow \argmin_{v \in tree.vertices} d(v, v_r)$\;
        \BlankLine
        \tcp{Steer Toward Random Point}
        \eIf{$d(v_n, v_r) \leq \delta_s$}{
            $v \leftarrow v_r$\;
        }{
            $\theta \leftarrow \arctan2(v_r.y - v_n.y, v_r.x - v_n.x)$\;
            $v.x \leftarrow v_n.x + \delta_s \cos(\theta)$\;
            $v.y \leftarrow v_n.y + \delta_s \sin(\theta)$\;
        }
        \BlankLine
        \tcp{Choose Best Parent}
        $parent \leftarrow -1$\;
        \If{no collision between $v_n$ and $v$}{
            $parent \leftarrow v_n$\;
        }
        \ForEach{vertex $v_i$ in $tree.vertices$}{
            \If{$d(v_i, v) < \delta_r$ \textbf{and} no collision between $v_i$ and $v$}{
                $cost_{new} \leftarrow tree.costs[v_i] + d(v_i, v)$\;
                \If{$parent = -1$ \textbf{or} $cost_{new} < tree.costs[parent] + d(parent, v)$}{
                    $parent \leftarrow v_i$\;
                }
            }
        }
        \If{$parent = -1$}{
            \textbf{continue}\tcp*{No valid parent found}
        }
        \BlankLine
        \textsc{AddVertex}$(v, parent)$\;
        $idx_v \leftarrow |tree.vertices| - 1$\;
        \BlankLine
        \tcp{Rewire Neighbors}
        \ForEach{vertex $v_i$ in $tree.vertices$}{
            \If{$d(v_i, v) < \delta_r$ \textbf{and} no collision between $v_i$ and $v$}{
                $cost_{via\_v} \leftarrow tree.costs[idx_v] + d(v, v_i)$\;
                \If{$tree.costs[i] > cost_{via\_v}$}{
                    $tree.parents[i] \leftarrow idx_v$\;
                    $tree.costs[i] \leftarrow cost_{via\_v}$\;
                }
            }
        }
        \BlankLine
        \tcp{Check Goal Reachability}
        \If{$d(v, P.goal) \leq \delta_s$ \textbf{and} no collision between $v$ and $P.goal$}{
            \textsc{AddVertex}$(P.goal, idx_v)$\;
            \textbf{break}\tcp*{Goal reached}
        }
        \BlankLine
        $iterations \leftarrow iterations + 1$\;
    }
    \caption{BuildRRT}\label{alg:rrt}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \SetKwProg{Fn}{Function}{:}{}
    
    \Fn{\textsc{RRTPath}$(P, \delta_s, \delta_r, I_{max})$}{
        \Input{Problem $P$, step size $\delta_s$, radius $\delta_r$, iterations $I_{max}$}
        \Output{Path from start to goal}
        \BlankLine
        \textsc{BuildRRT}$(P, \delta_s, \delta_r, I_{max})$\;
        $goal\_index \leftarrow |tree.vertices| - 1$\tcp*{Goal is last vertex}
        \Return{\textsc{ReconstructPath}$(goal\_index)$}
    }
    \caption{RRTPath - Main Path Planning Function}
    \label{RRTPath}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \Input{Problem $P$, step size $\delta_s$, radius $\delta_r$, max iterations $I$, \\
           bool $use\_intelligent\_sampling$, probabilities $p_{vertex}$, $p_{edge}$, \\
           number of edge samples $n_{edge}$}
    \Output{Number of iterations taken to build tree}
    \BlankLine
    
    \tcp{Precompute sampling points if using intelligent sampling}
    \If{$use\_intelligent\_sampling$}{
        $vertices_{obstacles} \leftarrow P.\textsc{VerticesObstacles}()$\;
        $points_{near\_obstacles} \leftarrow P.\textsc{PointsNearObstacles}(n_{edge})$\;
    }

    
    $iterations \leftarrow 0$\;
    \While{$iterations < I$}{

        \tcp{Sample point according to strategy}
        \eIf{$use\_intelligent\_sampling$}{
            $v_r \leftarrow \textsc{RandomSample\_Intelligent}(P, vertices_{obstacles}, p_{vertex}, points_{near\_obstacles}, p_{edge})$
        }{
            $v_r \leftarrow \textsc{RandomSample\_Naive}(P)$\;
        }
        
        \tcp{... rest of BuildRRT algorithm unchanged (see Algorithm \ref{alg:rrt})}
        \tcp{Find nearest, steer, choose parent, rewire, check goal...}
        \BlankLine
        
        $iterations \leftarrow iterations + 1$\;
    }
    
    \Return{$iterations$}
    \caption{BuildRRT - with Intelligent Sampling Option}\label{alg:rrt_intelligent}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \SetKwProg{Fn}{Function}{:}{}
    
    \Fn{\textsc{RandomSample\_Intelligent}$(P, V_{obs}, p_v, E_{obs}, p_e)$}{
        \Input{Problem $P$, obstacle vertices $V_{obs}$, probability $p_v$, edge points $E_{obs}$, probability $p_e$}
        \Output{Sampled point}
        $r \leftarrow$ random$(0, 1)$\;
        \eIf{$r < p_v$ \textbf{and} $V_{obs} \neq \emptyset$}{
            \Return{random element from $V_{obs}$}\tcp*{Near vertex}
        }{
            \eIf{$r < p_v + p_e$ \textbf{and} $E_{obs} \neq \emptyset$}{
                \Return{random element from $E_{obs}$}\tcp*{Near edge}
            }{
                \Return{\textsc{RandomSample\_Naive}$(P)$}\tcp*{Uniform}
            }
        }
    }
    \caption{RandomSample\_Intelligent - Strategic Sampling}\label{alg:intelligent_sample}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \footnotesize
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\textsc{VerticesObstacles}$(obstacles, x_{max}, y_{max})$}{
        \Input{List of obstacles, environment bounds}
        \Output{Vertices slightly outside obstacles}
        $V \leftarrow \emptyset$\;
        \ForEach{obstacle $obs$ in $obstacles$}{
            $corners \leftarrow$ 4 corner points of $obs$\;
            \For{$i \gets 0$ \KwTo $3$}{
                \If{$corners[i]$ not on environment boundary}{
                    $p \leftarrow$ shift $corners[i]$ slightly outward\tcp*{$\epsilon = 10^{-4}$}
                    Append $p$ to $V$\;
                }
            }
        }
        \Return{$V$}
    }
    \caption{VerticesObstacles - Extract Obstacle Vertices}
    \label{verticesObstacles}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \footnotesize
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\textsc{PointsNearObstacles}$(obstacles, N, x_{max}, y_{max})$}{
        \Input{Obstacles, target count $N$, environment bounds}
        \Output{Points distributed along obstacle edges}
        $E \leftarrow \emptyset$\;
        $P_{total} \leftarrow \sum_{obs} 2(obs.l_x + obs.l_y)$\tcp*{Total perimeter}
        \ForEach{obstacle $obs$ in $obstacles$}{
            $P_{obs} \leftarrow 2(obs.l_x + obs.l_y)$\;
            $n \leftarrow \lfloor N \cdot (P_{obs} / P_{total}) \rfloor$\tcp*{Points proportional to perimeter}
            \For{$i \gets 0$ \KwTo $n-1$}{
                $t \leftarrow i / n$\;
                $p \leftarrow$ point at position $t$ along perimeter of $obs$, shifted slightly outward\;
                \If{$p$ valid (not on boundary, not inside obstacles)}{
                    Append $p$ to $E$\;
                }
            }
        }
        \Return{$E$}
    }
    \caption{PointsNearObstacles - Sample Obstacle Edges}
    \label{PointsNearObstacles}
\end{algorithm}

\begin{algorithm}[H]
    \DontPrintSemicolon
    \footnotesize
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
    \Input{Problem $P$, $\delta_s$, $\delta_r$, $I$, intelligent params, $is\_second\_robot$, $path_{robot1}$}
    \Output{Iterations count}
    $tree_{cur} \leftarrow is\_second\_robot$ ? $tree_2$ : $tree_1$\;
    \If{intelligent sampling}{ Precompute $V_{obs}$ and $E_{obs}$\;}
    $iterations \leftarrow 0$\;
    \While{$iterations < I$}{
        $v_r \leftarrow$ sample point (intelligent or naive)\;
        \If{$v_r$ in obstacle}{\textbf{continue}\;}
        $v_n \leftarrow$ nearest vertex in $tree_{cur}$ to $v_r$\;
        $v \leftarrow$ steer from $v_n$ toward $v_r$ at max distance $\delta_s$\;
        \tcp{Choose best parent with collision checks}
        $parent \leftarrow -1$\;
        \If{no collision($v_n$, $v$) \textbf{and not} edge collision with $path_{robot1}$}{
            $parent \leftarrow v_n$\;
        }
        \ForEach{$v_i$ in $tree_{cur}$ within radius $\delta_r$ of $v$}{
            \If{no collision($v_i$, $v$) \textbf{and not} edge collision with $path_{robot1}$}{
                \If{$parent = -1$ \textbf{or} cost via $v_i$ is better}{
                    $parent \leftarrow v_i$\;
                }
            }
        }
        \If{$parent = -1$}{\textbf{continue}\;}
        \textsc{AddVertex}$(tree_{cur}, v, parent)$; $idx_v \leftarrow |tree_{cur}| - 1$\;
        \If{\textbf{not} $is\_second\_robot$}{
            Rewire neighbors of $v$ in $tree_{cur}$\tcp*{Only for robot 1}
        }
        \If{goal reachable from $v$}{
            \textsc{AddVertex}$(tree_{cur}, goal, idx_v)$; \textbf{break}\;
        }
        $iterations \leftarrow iterations + 1$\;
    }
    \Return{$iterations$}
    \caption{BuildRRT - Multi-Robot Path Planning}\label{alg:rrt_2robots}
\end{algorithm}

\section{Visualization}

\begin{figure}[ht]
\centering
\includegraphics[width=0.4\textwidth]{assets/scenario0.png}\hspace{0.05\textwidth}%
\includegraphics[width=0.4\textwidth]{assets/scenario1.png}\\[0.5cm]
\includegraphics[width=0.4\textwidth]{assets/scenario2.png}\hspace{0.05\textwidth}%
\includegraphics[width=0.4\textwidth]{assets/scenario3.png}\\[0.5cm]
\includegraphics[width=0.4\textwidth]{assets/scenario4.png}
\caption{Test scenarios 0-4}
\label{fig:scenarios}
\end{figure}


\medskip


\end{document}