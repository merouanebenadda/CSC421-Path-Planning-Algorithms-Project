\documentclass{article}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{amsmath} % For math symbols
\usepackage{graphicx} % For including images
\usepackage{booktabs} % For table formatting
\usepackage{multirow} % For multirow in tables
\usepackage{float} % For float positioning option H
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algpseudocode}


\begin{document}
\title{INF421 PI\@: PATH PLANNING ALGORITHMS}
\author{Merouane Benadda, Antoine FÃ¨vre}

\maketitle

\textbf{Question 1.} We chose to implement the algorithm in C++, as it allows better performance. 
For visualization, we used Python with Matplotlib, as it provides a more convenient way to create visual representations of the results.

\medskip

\textbf{Question 2.} See the implementation in the file \texttt{scripts/visualize.py}.

\medskip

\textbf{Question 3.} See the implementation in the file \texttt{src/pso.cpp}.

\medskip

\textbf{Question 4.} See the implementation in the file \texttt{src/pso.cpp}.

\medskip

\textbf{Question 5.} See Algorithm~\ref{alg:pso} for the pseudocode.

\begin{algorithm}[!h]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

    \Input{Problem scenario $P$, iterations $I$, constants $c_1, c_2, w$}
    \Output{Global best path $g_{best}$ and its cost $f(g_{best})$}

    \BlankLine
    Initialize $g_{best}$ with the first particle's waypoints\;
    \For{$iter = 1$ \KwTo$I$}{
        \BlankLine
        \tcp{Evaluate Fitness and Update Memory}
        \ForEach{particle $p$ in swarm}{
            $cost \leftarrow \text{fitness}(p.waypoints, P)$\;
            
            \If{$cost < p.best\_cost$}{
                $p.best\_cost \leftarrow cost$\;
                $p.best\_waypoints \leftarrow p.waypoints$\;
            }
            
            \If{$cost < g_{best}.cost$}{
                $g_{best}.cost \leftarrow cost$\;
                $g_{best}.waypoints \leftarrow p.waypoints$\;
            }
        }

        \BlankLine
        \tcp{Update Kinematics}
        \ForEach{particle $p$ in swarm}{
            \For{each waypoint $i$ in path}{
                $r_1, r_2 \leftarrow \text{random}(0, 1)$\;
                
                \tcp{Velocity Update}
                $v_i \leftarrow w \cdot v_i + c_1 \cdot r_1 \cdot (p.best\_waypoints_i - p.waypoints_i) + c_2 \cdot r_2 \cdot (g_{best}.waypoints_i - p.waypoints_i)$\;
                
                \tcp{Position Update}
                $p.waypoints_i \leftarrow p.waypoints_i + v_i$\;
                
                \tcp{Boundary Constraint}
                $p.waypoints_i \leftarrow \text{clamp}(p.waypoints_i, P.\min, P.\max)$\;
            }
        }
    }
    \Return{$g_{best}$}
    \caption{Particle Swarm Optimization for Path Planning}\label{alg:pso}
\end{algorithm}

\medskip

\textbf{Question 6.} The complexity of the algorithm is $O(I \cdot N \cdot M)$, where $I$ is the number of iterations, $N$ is the number of particles in the swarm, and $M$ is the number of waypoints in each particle's path. 

Indeed, for each iteration, we evaluate the fitness of each particle, which takes $O(N \cdot M)$ time, since we compute the fitness by iterating over each waypoint in each particle's path. Then, we update the velocity and position of each particle, which also takes $O(N \cdot M)$ time, as we need to update each waypoint for each particle. Therefore, the overall complexity is $O(I \cdot N \cdot M)$.

\medskip

\textbf{Question 7.} See the implementation in the file \texttt{src/pso.cpp}.

\medskip

\textbf{Question 8.} For the basic PSO algorithm, we had to pick an important number of particles because, since our fitness function is quite simple (the euclidian distance plus infinity if the path crosses an obstacle), finding a first valid path is a matter of luck, and the more particles we have, the more likely we are to find a valid path that we can optimize.

As we can see in Figure~\ref{fig:scenarios}, the solutions are not always optimal.

\begin{verbatim}
const int NUM_PARTICLES = 100000;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 1000;
const double C1 = 2.0; // cognitive coefficient
const double C2 = 2.0; // social coefficient
const double W = 0.75;  // inertia weight
\end{verbatim}

\begin{figure}[ht]
\centering
\includegraphics[width=0.4\textwidth]{assets/scenario0.png}\hspace{0.05\textwidth}%
\includegraphics[width=0.4\textwidth]{assets/scenario1.png}\\[0.5cm]
\includegraphics[width=0.4\textwidth]{assets/scenario2.png}\hspace{0.05\textwidth}%
\includegraphics[width=0.4\textwidth]{assets/scenario3.png}\\[0.5cm]
\includegraphics[width=0.4\textwidth]{assets/scenario4.png}
\caption{Test scenarios 0-4}
\label{fig:scenarios}
\end{figure}

\medskip

\textbf{Question 9.}

The random restart method allows us to reduce the number of particles needed to find a valid path, as it gives the algorithm multiple chances to find a valid path by restarting the particles' positions after a certain number of iterations. This way, even if we start with a small number of particles, we can still find a valid path by giving the algorithm multiple attempts. The restart interval is sufficiently large to allow the particles to explore the search space and converge towards a good solution before being restarted.

\begin{verbatim}
const int NUM_PARTICLES = 1000;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 50000;
const int RESTART_INTERVAL = 2500;
\end{verbatim}


\medskip

\textbf{Question 10.} The cooling rate makes the temperature stay high for a longer time, which allows the algorithm to explore the search space more thoroughly and avoid getting stuck in local minima. We chose the initial temperature empirically, by testing different values and observing the convergence of the algorithm.


\begin{verbatim}
const int NUM_PARTICLES = 1000;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 30000;
const int RESTART_INTERVAL = 3000;
double initial_temperature = 100.0;
double cooling_rate = 0.99;
\end{verbatim}


\medskip

\textbf{Question 11.}

We chose a small stagnation threshold so the particles can quickly benefit from the dimensional learning when they are stuck in a local minimum. Since our fitness function is quite simple, it is easy for the particles to get stuck in local minima, especially in scenarios with many obstacles. By applying dimensional learning after a small number of iterations without improvement, we allow the particles to escape these local minima and explore new areas of the search space, which can lead to better solutions.

\begin{verbatim}
const int NUM_PARTICLES = 500;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 30000;
const int RESTART_INTERVAL = 5000;
double initial_temperature = 100.0;
double cooling_rate = 0.99;
int stagnation_threshold = 15;
\end{verbatim}

\medskip

\textbf{Question 12.} To improve the performance of the algorithm, we could refine the fitness function. Instead of simply being the euclidian distance plus infinity if the path crosses an obstacle, we can make it output the euclidian distance plus a penalty proportional to the distance crossed in the obstacles.

This way, the algorithm would converge faster, especially in cases with lots of obstacles, as it would be able to differentiate between paths that are close to the optimal one but cross an obstacle and paths that are far from the optimal one but do not cross any obstacle.

To do so, we compute the intersection of the path with the obstacles in \texttt{src/utils.cpp}. To avoid any situation where the alogorithm would prefer crossing an obstacle to reduce the distance, we can set the penalty to be a large constant multiplied by the distance crossed in the obstacle.

\begin{verbatim}
const int NUM_PARTICLES = 200;
const int NUM_WAYPOINTS = 5;
const int NUM_ITERATIONS = 30000;
const int RESTART_INTERVAL = 2500;
double initial_temperature = 100.0;
double cooling_rate = 0.999;
int stagnation_threshold = 15;
\end{verbatim}

\medskip


\begin{table}[ht]
\centering
\caption{Performance Comparison across All Test Scenarios and Methods}
\label{tab:all_results}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}l|rr|rr|rr|rr|rr@{}}
\toprule
\multirow{2}{*}{\textbf{Scenario}} & \multicolumn{2}{c|}{\textbf{Basic PSO}} & \multicolumn{2}{c|}{\textbf{Random Restart}} & \multicolumn{2}{c|}{\textbf{Annealing PSO}} & \multicolumn{2}{c|}{\textbf{Dim. Learning}} & \multicolumn{2}{c}{\textbf{DL + Refined Fitness}} \\
& \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} & \textbf{Cost} & \textbf{Time (s)} \\
\midrule
0 & 1443.33 & 22.72 & 1443.33 & 10.65 & 1443.33 & 7.82 & 1443.33 & 5.00 & 1443.33 & 1.29 \\
1 & 1449.06 & 31.06 & 1449.06 & 15.17 & 1449.06 & 10.70 & 1449.06 & 7.38 & 1449.12 & 1.45 \\
2 & 1522.56 & 37.66 & 1505.19 & 18.20 & 1505.19 & 12.99 & 1505.65 & 7.32 & 1505.19 & 1.91 \\
3 & 1524.98 & 34.25 & 1522.54 & 16.23 & 1522.90 & 10.43 & 1522.52 & 6.36 & 1522.86 & 2.23 \\
4 & 1961.92 & 35.89 & 1946.06 & 16.81 & 1948.74 & 10.55 & 1946.45 & 6.33 & 1941.36 & 2.30 \\
\bottomrule
\end{tabular}%
}
\end{table}

As we can see in Table~\ref{tab:all_results}, adding the different improvements to the basic PSO algorithm allows us to significantly reduce the cost of the solution and the time needed to find it.

\medskip

\textbf{Question 13.}

To represent the tree, we use three vectors. For each vertex index, we have the corresponding point in the \texttt{vertices} vector, the index of its parent vertex in the \texttt{parents} vector, and the distance of the path from the root to the vertex in the \texttt{costs} vector. This way, we can easily reconstruct the path from any vertex to the root by following the parent indices, and efficiently compute the length of any path in the tree when updating parents in the rewiring process.
See the implementation in the file \texttt{src/RRT.hpp}.

\medskip

\textbf{Question 14.}

To correspond to the conventions taken before, the method gives the vertices coordinates, from the root to the goal, exluding the extremities.
See the implementation in the files \texttt{src/RRT.hpp} and \texttt{src/RRT.cpp}.

\medskip





\begin{algorithm}
\caption{AddVertex}
\begin{algorithmic}[1]
\Procedure{AddVertex}{$v$, $parent\_index$}
    \State $tree.vertices \gets tree.vertices \cup \{v\}$
    \State $tree.parents \gets tree.parents \cup \{parent\_index\}$
    \State $cost \gets tree.costs[parent\_index] + d(tree.vertices[parent\_index], v)$
    \State $tree.costs \gets tree.costs \cup \{cost\}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{ReconstructPath}
\begin{algorithmic}[1]
\Procedure{ReconstructPath}{$vertex\_index$}
    \State $path \gets \emptyset$
    \State $current \gets tree.parents[vertex\_index]$ \Comment{Start from parent of goal}
    \While{$tree.parents[current] \neq -1$}
        \State $path \gets path \cup \{tree.vertices[current]\}$
        \State $current \gets tree.parents[current]$
    \EndWhile
    \State \textbf{reverse}$(path)$ \Comment{Get path from start to goal}
    \State \Return $path$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{BuildRRT (RRT* variant)}
\begin{algorithmic}[1]
\Procedure{BuildRRT}{$problem$, $\delta_s$, $\delta_r$, $max\_iterations$}
    \State $iterations \gets 0$
    \While{$iterations < max\_iterations$}
        \State $v_r \gets$ \Call{RandomPoint}{$problem.x_{max}$, $problem.y_{max}$}
        \If{\Call{PointInObstacles}{$v_r$, $obstacles$}}
            \State \textbf{continue} \Comment{Skip if inside obstacle}
        \EndIf
        
        \State \Comment{Find nearest vertex}
        \State $v_n \gets \argmin_{v \in tree.vertices} d(v, v_r)$
        
        \State \Comment{Steer towards $v_r$ at max distance $\delta_s$}
        \If{$d(v_n, v_r) \leq \delta_s$}
            \State $v \gets v_r$
        \Else
            \State $\theta \gets \arctan2(v_r.y - v_n.y, v_r.x - v_n.x)$
            \State $v \gets (v_n.x + \delta_s \cos\theta, v_n.y + \delta_s \sin\theta)$
        \EndIf
        
        \State \Comment{Choose best parent within radius $\delta_r$ (RRT*)}
        \State $parent \gets \bot$
        \If{\textbf{not} \Call{Collision}{$v_n$, $v$}}
            \State $parent \gets v_n$
        \EndIf
        \For{$v_i \in tree.vertices$}
            \If{$d(v_i, v) < \delta_r$ \textbf{and not} \Call{Collision}{$v_i$, $v$}}
                \State $cost_{new} \gets tree.costs[v_i] + d(v_i, v)$
                \If{$parent = \bot$ \textbf{or} $cost_{new} < tree.costs[parent] + d(parent, v)$}
                    \State $parent \gets v_i$
                \EndIf
            \EndIf
        \EndFor
        
        \If{$parent = \bot$}
            \State \textbf{continue} \Comment{No valid parent found}
        \EndIf
        
        \State \Call{AddVertex}{$v$, $parent$}
        \State $idx_v \gets |tree.vertices| - 1$
        
        \State \Comment{Rewire neighbors (RRT*)}
        \For{$i \gets 0$ \textbf{to} $|tree.vertices| - 1$}
            \If{$d(tree.vertices[i], v) < \delta_r$ \textbf{and not} \Call{Collision}{$tree.vertices[i]$, $v$}}
                \State $cost_{through\_v} \gets tree.costs[idx_v] + d(v, tree.vertices[i])$
                \If{$tree.costs[i] > cost_{through\_v}$}
                    \State $tree.parents[i] \gets idx_v$
                    \State $tree.costs[i] \gets cost_{through\_v}$
                \EndIf
            \EndIf
        \EndFor
        
        \State \Comment{Check if goal is reachable}
        \If{$d(v, goal) \leq \delta_s$ \textbf{and not} \Call{Collision}{$v$, $goal$}}
            \State \Call{AddVertex}{$goal$, $idx_v$}
            \State \textbf{break} \Comment{Goal reached}
        \EndIf
        
        \State $iterations \gets iterations + 1$
    \EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{RRT Path Planning}
\begin{algorithmic}[1]
\Procedure{RRTPath}{$problem$, $\delta_s$, $\delta_r$, $max\_iterations$}
    \State \Call{BuildRRT}{$problem$, $\delta_s$, $\delta_r$, $max\_iterations$}
    \State $goal\_index \gets |tree.vertices| - 1$
    \State \Return \Call{ReconstructPath}{$goal\_index$}
\EndProcedure
\end{algorithmic}
\end{algorithm}


\textbf{Question 15.}

\medskip

\textbf{Question 16.}

\medskip

\textbf{Question 17.}

\medskip

\textbf{Question 18.}

\medskip

\textbf{Question 19.}

\medskip

\textbf{Question 20.}

\medskip

\textbf{Question 21.}

\medskip

\textbf{Question 22.}

\medskip

\textbf{Question 23.}

\medskip

\textbf{Question 24.}

\medskip

\textbf{Question 25.} We use Github for version control and to share our code. It is a very convenient tool for collaboration, as it allows us to easily track changes, manage branches, and review each other's code.

We also used GitHub Copilot to help us with some of the redundant code, such as the verification of the input or the geometry functions. It is a very useful tool for increasing productivity, as it can generate code snippets based on the context, which saves us time and allows us to focus on the more complex parts of the implementation. However, we used it very carefully, as it can sometimes generate incorrect code, so we always reviewed the generated code line by line to ensure its correctness.

\medskip

\end{document}